{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_over_DenseNet121.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex4lPa6F_ndg",
        "colab_type": "text"
      },
      "source": [
        "# Training DenseNet121 Over CIFAR10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3PrxSxN8lpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import os\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, DepthwiseConv2D\n",
        "from keras.layers import Concatenate\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, LearningRateScheduler, CSVLogger\n",
        "from keras.callbacks import Callback\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "import copy\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNdQ0X9U_NRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 85\n",
        "l = 6 # no of layers in dense block\n",
        "num_filter = 35 # growth rate k\n",
        "compression = 1.0\n",
        "dropout_rate = 0.20\n",
        "\n",
        "# CCP Augmented Training\n",
        "ccp_augment = False #For augmented CCP attack training dataset, change ccp_augment=False to ccp_augment=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux26BoYDALvd",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhjvcVnz_Z6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CCP ATTACK FUNCTIONS\n",
        "def change_brightness(image, alpha, beta):\n",
        "  new_image = np.zeros(image.shape, np.int64)\n",
        "  new_image = np.clip( alpha*image + beta, 0, 255)\n",
        "  return new_image\n",
        "\t\n",
        "def CCP_Attack_Brightness(image, transform):\n",
        "\timg = copy.copy(image)\n",
        "\tfor channel in range(img.shape[2]):\n",
        "\t\ttemp1 = image[:,:,0]\n",
        "\t\ttemp2 = image[:,:,1]\n",
        "\t\ttemp3 = image[:,:,2]\n",
        "\n",
        "\t\ttemp = temp1 * transform[channel][0] + temp2 * transform[channel][1] + temp3 * transform[channel][2]\n",
        "\n",
        "\t\timg[:,:,channel] = temp/3\n",
        "\n",
        "\timg1 = change_brightness(img, 2, 0)\n",
        "\treturn img1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey-zod86_OCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# CCP Augmentation\n",
        "# CCP Augmentation\n",
        "if ccp_augment:\n",
        "  print('CCP augmented included!')\n",
        "  # Copy Dataset\n",
        "  x_train_trans = copy.copy(x_train)\n",
        "\n",
        "  # Intializing at each transformation [0,1.0]\n",
        "  a = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "  b = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "  c = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "  transform = np.array([a,b,c]) \n",
        "\n",
        "\n",
        "  for test in range(len(x_train)):\n",
        "    \n",
        "    ## Comment or Uncomment this for Fixed or Variable settings respectively.\n",
        "    a = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "    b = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "    c = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "    transform = np.array([a,b,c])\n",
        "\n",
        "    ## Copy Image\n",
        "    img = copy.copy(x_train[test])\n",
        "\n",
        "    ## CCP Attack\n",
        "    x_train_trans[test] = CCP_Attack_Brightness(img, transform)\n",
        "\n",
        "  # Including augmented training dataset, i.e., 1,00,000 training images total\n",
        "  x_train = np.vstack((x_train,x_train_trans))\n",
        "  y_train = np.vstack((y_train,y_train))\n",
        "    \n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "def preprocess_data(data_set):\n",
        "    mean = np.array([125.3, 123.0, 113.9])\n",
        "    std = np.array([63.0, 62.1, 66.7])\n",
        "\n",
        "    data_set -= mean\n",
        "    data_set /= std\n",
        "    return data_set\n",
        "\n",
        "x_train = preprocess_data(x_train)\n",
        "x_test = preprocess_data(x_test)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTEIgP8SAQeG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data augementation\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.125,\n",
        "    height_shift_range=0.125,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    zoom_range=0.10\n",
        ")\n",
        "\n",
        "datagen_train.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfi9oCSKAZ0G",
        "colab_type": "text"
      },
      "source": [
        "#Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R2RN-InAYNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQmi-s0yAdiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UugdqxQ3AfY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li2jEnLKAg-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7Dx7VgTAklq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avkRnBVXAqGb",
        "colab_type": "text"
      },
      "source": [
        "# Callbacks and Model Compiling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd7TxA_4AmPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 5, min_lr = 0.000001)\n",
        "\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
        "\n",
        "def decay_fn(epoch, lr):\n",
        "    if epoch < 50:\n",
        "        return 0.001\n",
        "    elif epoch >= 50 and epoch < 75:\n",
        "        return 0.0001\n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(decay_fn)\n",
        "\n",
        "csv_logger = CSVLogger('training.log')\n",
        "\n",
        "filepath = \"{epoch:03d}-{val_acc:.3f}.hdf5\"\n",
        "model_chkpt = ModelCheckpoint(filepath, monitor = \"val_loss\", save_best_only=True, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGFoM5hnAvh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),#SGD(lr=0.1, momentum=0.9, decay=0.0001, nesterov=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SOWIgwZAyab",
        "colab_type": "text"
      },
      "source": [
        "# Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvBf0-XMAzqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "    datagen_train.flow(x_train, y_train, batch_size=batch_size),\n",
        "    steps_per_epoch=(len(x_train)/batch_size)*5,\n",
        "    epochs=epochs,\n",
        "    verbose = 1,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks = [lr_scheduler, csv_logger, model_chkpt]\n",
        ")\n",
        "\n",
        "model.save('densenet_cifar10.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj7AsNuyA5-s",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjF4F0bjA7Wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTWLLkC1BLNR",
        "colab_type": "text"
      },
      "source": [
        "# Testing on CCP Attack\n",
        "### Testing the CIFAR10 test dataset with s=2 and b=0\n",
        "#### (CCP_F and CCP_V)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6lQfY7tBAeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Model\n",
        "import keras\n",
        "new_model = keras.models.load_model('densenet_cifar10.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHPAz4JfBSnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_data(data_set):\n",
        "    mean = np.array([125.3, 123.0, 113.9])\n",
        "    std = np.array([63.0, 62.1, 66.7])\n",
        "\n",
        "    data_set -= mean\n",
        "    data_set /= std\n",
        "    return data_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw6oE9RABYTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test Over CCP\n",
        "\n",
        "# Load Dataset\n",
        "(x_train1, y_train1), (x_test1, y_test1) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Copy Test Set\n",
        "x_test1_trans = copy.copy(x_test1)\n",
        "# nois = np.random.randint(low=0, high=256, size=(32, 32, 3))\n",
        "a = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "b = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "c = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "transform1 = np.array([a,b,c]) \n",
        "\n",
        "for test in range(len(x_test1_trans)):\n",
        "\n",
        "  ## Comment or Uncomment below for Fixed or Variable settings respectively.\n",
        "  # a = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "  # b = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "  # c = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "  # transform1 = np.array([a,b,c])\n",
        "\n",
        "  # Copy the test image\n",
        "  img = copy.copy(x_test1_trans[test])\n",
        "\n",
        "  # CCP Attack\n",
        "  x_test1_trans[test] = CCP_Attack_Brightness(img,transform1)\n",
        "\n",
        "\n",
        "# Convert to FLOAT32\n",
        "x_test1_trans = x_test1_trans.astype('float32')\n",
        "\n",
        "# Preprocess Transformed Test Data for testing\n",
        "x_test1_trans = preprocess_data(x_test1_trans)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_test1 = keras.utils.to_categorical(y_test1, 10)\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "scores = new_model.evaluate(x_test1_trans, y_test1, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}