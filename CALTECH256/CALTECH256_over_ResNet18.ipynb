{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CALTECH256_over_ResNet18.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51De_RcTLnoF",
        "colab_type": "text"
      },
      "source": [
        "# Training CALTECH256 over ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mF4Ty3MLt-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install git+https://github.com/qubvel/classification_models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY6TEuItKGr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from classification_models.keras import Classifiers\n",
        "import tensorflow as tf\n",
        "import keras_preprocessing\n",
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wT_RWzRNWyt",
        "colab_type": "text"
      },
      "source": [
        "#Transfer Learning of ResNet18 with pre-trained imagenet weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gw7-CA7L3Wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "base_model = ResNet18(input_shape=(256,256,3), weights= 'imagenet', include_top=False)\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQgIJ325Nh6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes=257\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "output = keras.layers.Dense(n_classes, activation='softmax')(x)\n",
        "model = keras.models.Model(inputs=[base_model.input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xGIAvYyNx0F",
        "colab_type": "text"
      },
      "source": [
        "# Load Dataset with flow_from_directory\n",
        "\n",
        "#### Dataset: [CALTECH256](http://www.vision.caltech.edu/Image_Datasets/Caltech256/)\n",
        "\n",
        "#### Before proceeding further divide the CALTECH256 dataset into train and test folders with 80% of images for training set and 20% images for testset from total 30,607\n",
        "\n",
        "##### Note: Similarly, for CCP augmented training, using the divided training set (i.e., 24485 images), create CCP attacked images of training images and include them in the divided folder(i.e., total 48970 images in training for CCP augmented training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg5JoogRNu24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAINING_DIR = \"./Caltech256/train\"\n",
        "training_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "VALIDATION_DIR = \"./Caltech256/test\"\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\tTRAINING_DIR,\n",
        "\ttarget_size=(256,256),\n",
        "\tclass_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\tVALIDATION_DIR,\n",
        "\ttarget_size=(256,256),\n",
        "\tclass_mode='categorical'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAzfXRYDQPA1",
        "colab_type": "text"
      },
      "source": [
        "### Create numpy arrays of Test Dataset (to keep track of same test data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxeg1ZWxQMe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_classes = os.listdir(\"Caltech_256/test/\")\n",
        "\n",
        "count = 0\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "for eachclass in all_classes:\n",
        "    images = glob.glob('Caltech_256/test/' + eachclass + '/*.jpg')\n",
        "    for img in images:\n",
        "        read = cv2.imread(img)\n",
        "        image = cv2.cvtColor(read, cv2.COLOR_BGR2RGB)\n",
        "        test_images.append(image)\n",
        "        test_labels.append(count)\n",
        "    count += 1\n",
        "    \n",
        "    \n",
        "test_im = np.array(test_images)\n",
        "test_la = np.array(test_labels)\n",
        "\n",
        "np.save('test_images_caltech256_forresnet18.npy',test_im)\n",
        "np.save('test_labels_caltech256_forresnet18.npy',test_la)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UlMdIs0PX2j",
        "colab_type": "text"
      },
      "source": [
        "# Model Compile and Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJPltjQrS4Ld",
        "colab_type": "text"
      },
      "source": [
        "### First 20 Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYPJ79BNPamp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uG6Bz5WPc1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_generator, epochs=20, validation_data = validation_generator, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdSZ8JDFS2FD",
        "colab_type": "text"
      },
      "source": [
        "#### Next 20 Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJZL5dx6S1iA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdkgEW3vShNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_generator, epochs=20, validation_data = validation_generator, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsLeQUWkPk6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"Resnet18_over_Caltech256.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnFjFLLzQ-L2",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz7OMoHlRALu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "# initalize\n",
        "check = 0\n",
        "correct = 0\n",
        "\n",
        "# Load dataset and labels\n",
        "ims = np.load('test_images_caltech256_forresnet18.npy')\n",
        "lbs = np.load('test_labels_caltech256_forresnet18.npy')\n",
        "total = len(ims)\n",
        "\n",
        "# Count wrongly classified\n",
        "for ind in range(len(ims)):\n",
        "    temp = ims[ind]\n",
        "    image = temp/255.0\n",
        "    img_pred = np.expand_dims(image, axis=0)\n",
        "    result = new_model.predict(img_pred)\n",
        "    cl = np.argmax(result[0])\n",
        "    check = lbs[ind]\n",
        "    \n",
        "    if cl==check:\n",
        "        correct += 1\n",
        "        \n",
        "print(\" Accuracy - \" + str((correct/total) * 100) + '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuyE8_WzPqXj",
        "colab_type": "text"
      },
      "source": [
        "# Testing on CCP Attack\n",
        "### Testing the CALTECH test dataset with s=1 and b=30\n",
        "#### (CCP_F and CCP_V)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wTAu7IDP3uT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Model\n",
        "import keras\n",
        "model = keras.models.load_model('Resnet18_over_Caltech256.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIYgkFcrPwXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CCP ATTACK FUNCTIONS\n",
        "def change_brightness(image, alpha, beta):\n",
        "  new_image = np.zeros(image.shape, np.int64)\n",
        "  new_image = np.clip( alpha*image + beta, 0, 255)\n",
        "  return new_image\n",
        "\t\n",
        "def CCP_Attack_Brightness(image, transform):\n",
        "\timg = copy.copy(image)\n",
        "\tfor channel in range(img.shape[2]):\n",
        "\t\ttemp1 = image[:,:,0]\n",
        "\t\ttemp2 = image[:,:,1]\n",
        "\t\ttemp3 = image[:,:,2]\n",
        "\n",
        "\t\ttemp = temp1 * transform[channel][0] + temp2 * transform[channel][1] + temp3 * transform[channel][2]\n",
        "\n",
        "\t\timg[:,:,channel] = temp/3\n",
        "\n",
        "\timg1 = change_brightness(img, 1, 30)\n",
        "\treturn img1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lrxF7ZYQTOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test for CCP Attack\n",
        "import glob\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "# initalize\n",
        "check = 0\n",
        "correct = 0\n",
        "\n",
        "# Generate weights\n",
        "a = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "b = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "c = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "transform = np.array([a,b,c])\n",
        "\n",
        "# Load dataset and labels\n",
        "ims = np.load('test_images_caltech256_forresnet18.npy')\n",
        "lbs = np.load('test_labels_caltech256_forresnet18.npy')\n",
        "total = len(ims)\n",
        "\n",
        "# Count wrongly classified\n",
        "for ind in range(len(ims)):\n",
        "\n",
        "    ## Comment or Uncomment this for Fixed or Variable settings respectively.\n",
        "    a = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "    b = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "    c = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "    transform = np.array([a,b,c])\n",
        "\n",
        "    temp = CCP_Attack_Brightness(ims[ind], transform)\n",
        "    image = temp/255.0\n",
        "    img_pred = np.expand_dims(image, axis=0)\n",
        "    result = new_model.predict(img_pred)\n",
        "    cl = np.argmax(result[0])\n",
        "    check = lbs[ind]\n",
        "    \n",
        "    if cl==check:\n",
        "        correct += 1\n",
        "\n",
        "print(\" Accuracy - \" + str((correct/total) * 100) + '%')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
