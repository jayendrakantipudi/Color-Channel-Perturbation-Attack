{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CALTECH256_over_DenseNet121_org.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCkeCpzySIa9",
        "colab_type": "text"
      },
      "source": [
        "# Training CALTECH256 over DenseNet121"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cCBzeDYRp8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import keras_preprocessing\n",
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk9J6yW0SEgj",
        "colab_type": "text"
      },
      "source": [
        "#Transfer Learning of DenseNet121 with pre-trained imagenet weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfOYyuDlR15Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = tf.keras.applications.DenseNet121(weights='imagenet', include_top=False)\n",
        "\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(2048, activation='relu')(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "predictions = Dense(257, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "adam = Adam(lr=0.001)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR3BqG0ZSCGF",
        "colab_type": "text"
      },
      "source": [
        "# Load Dataset with flow_from_directory\n",
        "\n",
        "#### Dataset: [CALTECH256](http://www.vision.caltech.edu/Image_Datasets/Caltech256/)\n",
        "\n",
        "#### Before proceeding further divide the CALTECH256 dataset into train and test folders with 80% of images for training set and 20% images for testset from total 30,607\n",
        "\n",
        "##### Note: Similarly, for CCP augmented training, using the divided training set (i.e., 24485 images), create CCP attacked images of training images and include them in the divided folder(i.e., total 48970 images in training for CCP augmented training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIbo7fMcSCa3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAINING_DIR = \"./Caltech256/train\"\n",
        "training_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "VALIDATION_DIR = \"./Caltech256/test\"\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\tTRAINING_DIR,\n",
        "\ttarget_size=(256,256),\n",
        "\tclass_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\tVALIDATION_DIR,\n",
        "\ttarget_size=(256,256),\n",
        "\tclass_mode='categorical'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-xWJnUHSPVz",
        "colab_type": "text"
      },
      "source": [
        "### Create numpy arrays of Test Dataset (to keep track of same test data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTBYw7PdSO4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_classes = os.listdir(\"Caltech_256/test/\")\n",
        "\n",
        "count = 0\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "for eachclass in all_classes:\n",
        "    images = glob.glob('Caltech_256/test/' + eachclass + '/*.jpg')\n",
        "    for img in images:\n",
        "        read = cv2.imread(img)\n",
        "        image = cv2.cvtColor(read, cv2.COLOR_BGR2RGB)\n",
        "        test_images.append(image)\n",
        "        test_labels.append(count)\n",
        "    count += 1\n",
        "    \n",
        "    \n",
        "test_im = np.array(test_images)\n",
        "test_la = np.array(test_labels)\n",
        "\n",
        "np.save('test_images_caltech256_fordensenet121.npy',test_im)\n",
        "np.save('test_labels_caltech256_fordensenet121.npy',test_la)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmCSPmTTS8uG",
        "colab_type": "text"
      },
      "source": [
        "# Model Compile and Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-H3TmUuS_Sa",
        "colab_type": "text"
      },
      "source": [
        "### First 20 Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzV4boEHS8_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrNoBrHATBNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_generator, epochs=20, validation_data = validation_generator, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5oNuaTjTLbd",
        "colab_type": "text"
      },
      "source": [
        "### Next 20 Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yICy6EQ0TDTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLgOBwgtTEhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_generator, epochs=20, validation_data = validation_generator, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UasnS4mtTHRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"Densenet121_over_Caltech256.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2TXOmdbTXvj",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFf3TqR6TYIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "# initalize\n",
        "check = 0\n",
        "correct = 0\n",
        "\n",
        "# Load dataset and labels\n",
        "ims = np.load('test_images_caltech256_fordensenet121.npy')\n",
        "lbs = np.load('test_labels_caltech256_fordensenet121.npy')\n",
        "total = len(ims)\n",
        "\n",
        "# Count wrongly classified\n",
        "for ind in range(len(ims)):\n",
        "    temp = ims[ind]\n",
        "    image = temp/255.0\n",
        "    img_pred = np.expand_dims(image, axis=0)\n",
        "    result = new_model.predict(img_pred)\n",
        "    cl = np.argmax(result[0])\n",
        "    check = lbs[ind]\n",
        "    \n",
        "    if cl==check:\n",
        "        correct += 1\n",
        "        \n",
        "print(\" Accuracy - \" + str((correct/total) * 100) + '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh3oEUXnTiLE",
        "colab_type": "text"
      },
      "source": [
        "# Testing on CCP Attack\n",
        "### Testing the CALTECH test dataset with s=1 and b=30\n",
        "#### (CCP_F and CCP_V)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cEkeZRiTihl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Model\n",
        "import keras\n",
        "model = keras.models.load_model('Densenet121_over_Caltech256.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwQtBQgXTlqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CCP ATTACK FUNCTIONS\n",
        "def change_brightness(image, alpha, beta):\n",
        "  new_image = np.zeros(image.shape, np.int64)\n",
        "  new_image = np.clip( alpha*image + beta, 0, 255)\n",
        "  return new_image\n",
        "\t\n",
        "def CCP_Attack_Brightness(image, transform):\n",
        "\timg = copy.copy(image)\n",
        "\tfor channel in range(img.shape[2]):\n",
        "\t\ttemp1 = image[:,:,0]\n",
        "\t\ttemp2 = image[:,:,1]\n",
        "\t\ttemp3 = image[:,:,2]\n",
        "\n",
        "\t\ttemp = temp1 * transform[channel][0] + temp2 * transform[channel][1] + temp3 * transform[channel][2]\n",
        "\n",
        "\t\timg[:,:,channel] = temp/3\n",
        "\n",
        "\timg1 = change_brightness(img, 1, 30)\n",
        "\treturn img1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P25FLmknTsgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test for CCP Attack\n",
        "import glob\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "# initalize\n",
        "check = 0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Generate weights\n",
        "a = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "b = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "c = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "transform = np.array([a,b,c])\n",
        "\n",
        "# Load dataset and labels\n",
        "ims = np.load('test_images_caltech256_fordensenet121.npy')\n",
        "lbs = np.load('test_labels_caltech256_fordensenet121.npy')\n",
        "\n",
        "# Count wrongly classified\n",
        "for ind in range(len(ims)):\n",
        "\n",
        "    ## Comment or Uncomment this for Fixed or Variable settings respectively.\n",
        "    a = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "    b = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "    c = np.random.uniform(low=0.0, high=1.0, size=(3,))\n",
        "    transform = np.array([a,b,c])\n",
        "\n",
        "    temp = CCP_Attack_Brightness(ims[ind], transform)\n",
        "    image = temp/255.0\n",
        "    img_pred = np.expand_dims(image, axis=0)\n",
        "    result = new_model.predict(img_pred)\n",
        "    cl = np.argmax(result[0])\n",
        "    check = lbs[ind]\n",
        "    \n",
        "    if cl==check:\n",
        "        correct += 1\n",
        "\n",
        "print(\" Accuracy - \" + str((correct/total) * 100) + '%')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
